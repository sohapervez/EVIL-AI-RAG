# --- Provider Selection ---
# Options: ollama, openai, anthropic, groq
LLM_PROVIDER=openai
LLM_MODEL=llama3.1:70b
# Options: ollama, openai, huggingface
EMBEDDING_PROVIDER=huggingface
EMBEDDING_MODEL=BAAI/bge-base-en-v1.5
OLLAMA_BASE_URL=http://localhost:11434

# --- API Keys ---
# Replace with your actual API keys
OPENAI_API_KEY="your-openai-api-key-here"
OPENAI_API_BASE=https://your-custom-openai-endpoint.com/v1
ANTHROPIC_API_KEY=your-anthropic-api-key-here
GROQ_API_KEY=your-groq-api-key-here

# --- Parent-Child Chunking ---
PARENT_CHUNK_SIZE=4000
CHILD_CHUNK_SIZE=1000
CHILD_CHUNK_OVERLAP=200
USE_SEMANTIC_CHUNKING=false
USE_VISION_DESCRIPTIONS=false
USE_IMAGE_OCR=false
EXTRACT_IMAGES=false
EXTRACT_TABLES=true
USE_PARENT_CHILD_CHUNKING=false
SIMPLE_CHUNK_SIZE=2000
SIMPLE_CHUNK_OVERLAP=200

# --- Retrieval ---
TOP_K=5
USE_HYBRID_SEARCH=true
BM25_WEIGHT=0.0
USE_RERANKING=true
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# --- ChromaDB ---
CHROMA_PERSIST_DIR=./vectorstore
CHROMA_COLLECTION=research_papers
